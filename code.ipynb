{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd14059a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <ins><a href=\"https://ydata.ai/register\">Upgrade to ydata-sdk</a></ins>\n",
       "                <p>\n",
       "                    Improve your data and profiling with ydata-sdk, featuring data quality scoring, redundancy detection, outlier identification, text validation, and synthetic data generation.\n",
       "                </p>\n",
       "            </div>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rishi\\AppData\\Local\\Temp\\ipykernel_19732\\2244186339.py:3: DeprecationWarning: `import pandas_profiling` is going to be deprecated by April 1st. Please use `import ydata_profiling` instead.\n",
      "  from pandas_profiling import ProfileReport\n"
     ]
    }
   ],
   "source": [
    "!pip install ydata-profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a201c0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ydata_profiling import ProfileReport\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "afaa0da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re, warnings, math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option(\"display.max_columns\", 200)\n",
    "sns.set_theme(context=\"notebook\", style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0560078",
   "metadata": {},
   "outputs": [],
   "source": [
    "REPORT_DIR = \"eda_report\"\n",
    "os.makedirs(REPORT_DIR, exist_ok=True)\n",
    "\n",
    "def savefig(name):\n",
    "    path = os.path.join(REPORT_DIR, f\"{name}.png\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(path, dpi=140, bbox_inches=\"tight\")\n",
    "    print(f\" Saved: {path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f5990f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"CO2 Emissions_Canada.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d8fb84fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Cleaned columns: ['make', 'model', 'vehicle_class', 'engine_size_l_', 'cylinders', 'transmission', 'fuel_type', 'fuel_consumption_city_l_100_km_', 'fuel_consumption_hwy_l_100_km_', 'fuel_consumption_comb_l_100_km_', 'fuel_consumption_comb_mpg_', 'co2_emissions_g_km_']\n"
     ]
    }
   ],
   "source": [
    "def to_snake(name: str) -> str:\n",
    "    name = name.strip()\n",
    "    name = re.sub(r\"[^\\w\\s]\", \" \", name)      # replace punctuation with space\n",
    "    name = re.sub(r\"\\s+\", \"_\", name)          # collapse spaces to underscores\n",
    "    return name.lower()\n",
    "\n",
    "df.columns = [to_snake(c) for c in df.columns]\n",
    "print(\" Cleaned columns:\", list(df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01480be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shape: (7385, 12)\n",
      "\n",
      "Dtypes:\n",
      " make                                object\n",
      "model                               object\n",
      "vehicle_class                       object\n",
      "engine_size_l_                     float64\n",
      "cylinders                            int64\n",
      "transmission                        object\n",
      "fuel_type                           object\n",
      "fuel_consumption_city_l_100_km_    float64\n",
      "fuel_consumption_hwy_l_100_km_     float64\n",
      "fuel_consumption_comb_l_100_km_    float64\n",
      "fuel_consumption_comb_mpg_           int64\n",
      "co2_emissions_g_km_                  int64\n",
      "dtype: object\n",
      "\n",
      "Memory usage (MB): 2.47\n",
      "Saved preview_head.csv and preview_tail.csv\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nShape:\", df.shape)\n",
    "print(\"\\nDtypes:\\n\", df.dtypes)\n",
    "print(\"\\nMemory usage (MB):\", round(df.memory_usage(deep=True).sum() / 1e6, 2))\n",
    "\n",
    "# Save head/tail/info\n",
    "df.head(10).to_csv(os.path.join(REPORT_DIR, \"preview_head.csv\"), index=False)\n",
    "df.tail(10).to_csv(os.path.join(REPORT_DIR, \"preview_tail.csv\"), index=False)\n",
    "print(\"Saved preview_head.csv and preview_tail.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa716722",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.columns:\n",
    "    if df[col].dtype == \"object\":\n",
    "        # strip units and commas if they exist\n",
    "        cleaned = (df[col]\n",
    "                   .astype(str)\n",
    "                   .str.replace(\",\", \"\", regex=False)\n",
    "                   .str.replace(r\"[^\\d\\.\\-eE+]\", \"\", regex=True))\n",
    "        # convert where reasonable\n",
    "        maybe_num = pd.to_numeric(cleaned, errors=\"coerce\")\n",
    "        # only adopt if we meaningfully converted more than we lost\n",
    "        if maybe_num.notna().sum() >= max(10, int(0.3 * len(df))):\n",
    "            df[col] = maybe_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "37289fae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Dtypes after coercion:\n",
      " make                                object\n",
      "model                               object\n",
      "vehicle_class                       object\n",
      "engine_size_l_                     float64\n",
      "cylinders                            int64\n",
      "transmission                       float64\n",
      "fuel_type                           object\n",
      "fuel_consumption_city_l_100_km_    float64\n",
      "fuel_consumption_hwy_l_100_km_     float64\n",
      "fuel_consumption_comb_l_100_km_    float64\n",
      "fuel_consumption_comb_mpg_           int64\n",
      "co2_emissions_g_km_                  int64\n",
      "dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rishi\\AppData\\Local\\Temp\\ipykernel_19732\\2277697554.py:4: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  parsed = pd.to_datetime(df[col], errors=\"raise\", infer_datetime_format=True)\n",
      "C:\\Users\\rishi\\AppData\\Local\\Temp\\ipykernel_19732\\2277697554.py:4: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(df[col], errors=\"raise\", infer_datetime_format=True)\n",
      "C:\\Users\\rishi\\AppData\\Local\\Temp\\ipykernel_19732\\2277697554.py:4: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  parsed = pd.to_datetime(df[col], errors=\"raise\", infer_datetime_format=True)\n",
      "C:\\Users\\rishi\\AppData\\Local\\Temp\\ipykernel_19732\\2277697554.py:4: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(df[col], errors=\"raise\", infer_datetime_format=True)\n",
      "C:\\Users\\rishi\\AppData\\Local\\Temp\\ipykernel_19732\\2277697554.py:4: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  parsed = pd.to_datetime(df[col], errors=\"raise\", infer_datetime_format=True)\n",
      "C:\\Users\\rishi\\AppData\\Local\\Temp\\ipykernel_19732\\2277697554.py:4: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(df[col], errors=\"raise\", infer_datetime_format=True)\n",
      "C:\\Users\\rishi\\AppData\\Local\\Temp\\ipykernel_19732\\2277697554.py:4: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  parsed = pd.to_datetime(df[col], errors=\"raise\", infer_datetime_format=True)\n",
      "C:\\Users\\rishi\\AppData\\Local\\Temp\\ipykernel_19732\\2277697554.py:4: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(df[col], errors=\"raise\", infer_datetime_format=True)\n"
     ]
    }
   ],
   "source": [
    "for col in df.columns:\n",
    "    if df[col].dtype == \"object\":\n",
    "        try:\n",
    "            parsed = pd.to_datetime(df[col], errors=\"raise\", infer_datetime_format=True)\n",
    "            # adopt if sufficient success\n",
    "            if parsed.notna().mean() > 0.8:\n",
    "                df[col] = pd.to_datetime(df[col], errors=\"coerce\")\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "print(\"\\n Dtypes after coercion:\\n\", df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f74a1b25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Missing values (top):\n",
      "               missing  missing_%\n",
      "transmission      295   3.994584\n",
      "Saved: missing_summary.csv\n",
      "\n",
      " Duplicate rows: 1140\n"
     ]
    }
   ],
   "source": [
    "def missing_table(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    mis = data.isna().sum()\n",
    "    pct = 100 * mis / len(data)\n",
    "    out = (pd.DataFrame({\"missing\": mis, \"missing_%\": pct})\n",
    "           .loc[mis.sort_values(ascending=False).index])\n",
    "    return out[out[\"missing\"] > 0]\n",
    "\n",
    "missing_summary = missing_table(df)\n",
    "missing_summary.to_csv(os.path.join(REPORT_DIR, \"missing_summary.csv\"))\n",
    "print(\"\\n Missing values (top):\\n\", missing_summary.head(20))\n",
    "print(\"Saved: missing_summary.csv\")\n",
    "\n",
    "dup_count = df.duplicated().sum()\n",
    "print(f\"\\n Duplicate rows: {dup_count}\")\n",
    "if dup_count:\n",
    "    df_nodup = df.drop_duplicates()\n",
    "else:\n",
    "    df_nodup = df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2dd0bb1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: describe_numeric.csv (and describe_categorical.csv)\n"
     ]
    }
   ],
   "source": [
    "num_cols = [c for c in df.columns if pd.api.types.is_numeric_dtype(df[c])]\n",
    "cat_cols = [c for c in df.columns if c not in num_cols and df[c].dtype.name != \"datetime64[ns]\"]\n",
    "\n",
    "desc_num = df[num_cols].describe().T\n",
    "desc_cat = df[cat_cols].describe().T if cat_cols else pd.DataFrame()\n",
    "\n",
    "desc_num.to_csv(os.path.join(REPORT_DIR, \"describe_numeric.csv\"))\n",
    "if not desc_cat.empty:\n",
    "    desc_cat.to_csv(os.path.join(REPORT_DIR, \"describe_categorical.csv\"))\n",
    "print(\"Saved: describe_numeric.csv\", \"(and describe_categorical.csv)\" if not desc_cat.empty else \"\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3e32b46d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Saved: eda_report\\dist_engine_size_l_.png\n",
      " Saved: eda_report\\dist_cylinders.png\n",
      " Saved: eda_report\\dist_transmission.png\n",
      " Saved: eda_report\\dist_fuel_consumption_city_l_100_km_.png\n",
      " Saved: eda_report\\dist_fuel_consumption_hwy_l_100_km_.png\n",
      " Saved: eda_report\\dist_fuel_consumption_comb_l_100_km_.png\n",
      " Saved: eda_report\\dist_fuel_consumption_comb_mpg_.png\n",
      " Saved: eda_report\\dist_co2_emissions_g_km_.png\n"
     ]
    }
   ],
   "source": [
    "max_hists = min(12, len(num_cols))\n",
    "for col in num_cols[:max_hists]:\n",
    "    plt.figure(figsize=(6,4))\n",
    "    sns.histplot(df[col].dropna(), bins=30, kde=True)\n",
    "    plt.title(f\"Distribution: {col}\")\n",
    "    savefig(f\"dist_{col}\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "90385065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Saved: eda_report\\bar_make.png\n",
      " Saved: eda_report\\bar_model.png\n",
      " Saved: eda_report\\bar_vehicle_class.png\n",
      " Saved: eda_report\\bar_fuel_type.png\n"
     ]
    }
   ],
   "source": [
    "for col in cat_cols[:8]:\n",
    "    plt.figure(figsize=(7,4))\n",
    "    vc = df[col].astype(str).value_counts().head(15)\n",
    "    sns.barplot(x=vc.values, y=vc.index)\n",
    "    plt.title(f\"Top categories: {col}\")\n",
    "    plt.xlabel(\"count\"); plt.ylabel(col)\n",
    "    savefig(f\"bar_{col}\")\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f2871180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Saved: eda_report\\corr_heatmap.png\n",
      "Saved: correlation_pearson.csv & corr_heatmap.png\n"
     ]
    }
   ],
   "source": [
    "if len(num_cols) >= 2:\n",
    "    corr = df[num_cols].corr(numeric_only=True, method=\"pearson\")\n",
    "    corr.to_csv(os.path.join(REPORT_DIR, \"correlation_pearson.csv\"))\n",
    "    plt.figure(figsize=(min(12, 0.6*len(num_cols)+4), min(10, 0.6*len(num_cols)+4)))\n",
    "    sns.heatmap(corr, annot=False, cmap=\"viridis\", center=0)\n",
    "    plt.title(\"Correlation Heatmap (Pearson)\")\n",
    "    savefig(\"corr_heatmap\")\n",
    "    plt.close()\n",
    "    print(\"Saved: correlation_pearson.csv & corr_heatmap.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "28350a2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Outlier columns (top 10):\n",
      "                                  outliers_iqr  non_null  outlier_%\n",
      "fuel_consumption_hwy_l_100_km_            208      7385   2.816520\n",
      "cylinders                                 196      7385   2.654028\n",
      "fuel_consumption_comb_l_100_km_           142      7385   1.922817\n",
      "engine_size_l_                            137      7385   1.855112\n",
      "fuel_consumption_city_l_100_km_           132      7385   1.787407\n",
      "fuel_consumption_comb_mpg_                114      7385   1.543670\n",
      "co2_emissions_g_km_                        80      7385   1.083277\n",
      "transmission                                0      7090   0.000000\n",
      " Saved: outliers_iqr_summary.csv\n"
     ]
    }
   ],
   "source": [
    "def iqr_outlier_counts(s: pd.Series):\n",
    "    q1, q3 = s.quantile(0.25), s.quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    if iqr == 0 or pd.isna(iqr):\n",
    "        return 0\n",
    "    lo, hi = q1 - 1.5*iqr, q3 + 1.5*iqr\n",
    "    return int(((s < lo) | (s > hi)).sum())\n",
    "\n",
    "outlier_summary = pd.DataFrame({\n",
    "    \"outliers_iqr\": {c: iqr_outlier_counts(df[c].dropna()) for c in num_cols},\n",
    "    \"non_null\": {c: int(df[c].notna().sum()) for c in num_cols},\n",
    "})\n",
    "outlier_summary[\"outlier_%\"] = (100 * outlier_summary[\"outliers_iqr\"] / outlier_summary[\"non_null\"].clip(lower=1))\n",
    "outlier_summary = outlier_summary.sort_values(\"outlier_%\", ascending=False)\n",
    "outlier_summary.to_csv(os.path.join(REPORT_DIR, \"outliers_iqr_summary.csv\"))\n",
    "print(\"\\nOutlier columns (top 10):\\n\", outlier_summary.head(10))\n",
    "print(\" Saved: outliers_iqr_summary.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ef537dd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ℹ No obvious CO2 target column found. Skipping target-aware plots.\n"
     ]
    }
   ],
   "source": [
    "possible_targets = [\n",
    "    \"co2_emissions_g_km\", \"co2_emissions_g_per_km\", \"co2_emissions_gkm\",\n",
    "    \"co2_emissions\", \"co2_emissions_g/_km\", \"co2_emissions(g/km)\".replace(\"(\", \"_\").replace(\")\", \"\").replace(\"/\", \"_\").lower()\n",
    "]\n",
    "target_col = None\n",
    "for cand in possible_targets:\n",
    "    if cand in df.columns:\n",
    "        target_col = cand\n",
    "        break\n",
    "\n",
    "if target_col:\n",
    "    print(f\"\\nDetected target column: {target_col}\")\n",
    "    # scatter vs top correlated numeric features\n",
    "    if len(num_cols) > 1:\n",
    "        corrs = df[num_cols].corr(numeric_only=True)[target_col].dropna().abs().sort_values(ascending=False)\n",
    "        for feat in [c for c in corrs.index if c != target_col][:6]:\n",
    "            plt.figure(figsize=(6,4))\n",
    "            sns.scatterplot(x=df[feat], y=df[target_col], alpha=0.5)\n",
    "            plt.title(f\"{target_col} vs {feat}\")\n",
    "            savefig(f\"target_scatter_{target_col}_vs_{feat}\")\n",
    "            plt.close()\n",
    "\n",
    "    # boxplots by top categoricals\n",
    "    for col in cat_cols[:5]:\n",
    "        top = df[col].value_counts().index[:8]\n",
    "        plt.figure(figsize=(8,4))\n",
    "        sns.boxplot(x=df[col].where(df[col].isin(top)), y=df[target_col])\n",
    "        plt.title(f\"{target_col} by {col} (top cats)\")\n",
    "        plt.xticks(rotation=30, ha=\"right\")\n",
    "        savefig(f\"target_box_{target_col}_by_{col}\")\n",
    "        plt.close()\n",
    "else:\n",
    "    print(\"\\nℹ No obvious CO2 target column found. Skipping target-aware plots.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "31d23a55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: data_dictionary.csv\n"
     ]
    }
   ],
   "source": [
    "def data_dictionary(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    for c in data.columns:\n",
    "        dtype = str(data[c].dtype)\n",
    "        nunique = data[c].nunique(dropna=True)\n",
    "        missing = data[c].isna().sum()\n",
    "        example = data[c].dropna().iloc[0] if data[c].notna().any() else None\n",
    "        rows.append({\"column\": c, \"dtype\": dtype, \"nunique\": nunique,\n",
    "                     \"missing\": missing, \"example_value\": example})\n",
    "    return pd.DataFrame(rows).sort_values(\"column\")\n",
    "\n",
    "dd = data_dictionary(df)\n",
    "dd.to_csv(os.path.join(REPORT_DIR, \"data_dictionary.csv\"), index=False)\n",
    "print(\"Saved: data_dictionary.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "16980e28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:00<00:00, 945.57it/s]00:01,  7.20it/s, Describe variable: co2_emissions_g_km_]    \n",
      "Summarize dataset: 100%|██████████| 85/85 [00:05<00:00, 15.41it/s, Completed]                                                               \n",
      "Generate report structure: 100%|██████████| 1/1 [00:02<00:00,  2.12s/it]\n",
      "Render HTML: 100%|██████████| 1/1 [00:02<00:00,  2.18s/it]\n",
      "Export report to file: 100%|██████████| 1/1 [00:00<00:00, 39.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Profiling report saved: eda_report\\profile_report.html\n",
      "\n",
      "Done! Check the 'eda_report' folder for figures & summaries.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from ydata_profiling import ProfileReport\n",
    "profile = ProfileReport(df, explorative=True, title=\"CO2 Emissions — Automated EDA\")\n",
    "html_path = os.path.join(REPORT_DIR, \"profile_report.html\")\n",
    "profile.to_file(html_path)\n",
    "print(f\"Profiling report saved: {html_path}\")\n",
    "\n",
    "\n",
    "print(\"\\nDone! Check the 'eda_report' folder for figures & summaries.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
